{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from truthful_counterfactuals.utils import EXPERIMENTS_PATH\n",
    "from truthful_counterfactuals.utils import render_latex, latex_table\n",
    "from truthful_counterfactuals.metrics import threshold_error_reduction\n",
    "\n",
    "PATH = os.getcwd()\n",
    "NUM_BINS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing the results...\n",
      " * processing aqsoldb\n",
      " * processing lipop\n",
      " * processing compas\n",
      " * processing qm9_energy\n",
      " * processing qm9_dipole\n"
     ]
    }
   ],
   "source": [
    "results_map = {\n",
    "    'aqsoldb': {\n",
    "        'dataset': 'AqSolDB',\n",
    "        'property': 'logS',\n",
    "        'paths': [\n",
    "            os.path.join(EXPERIMENTS_PATH, 'results', 'quantify_uncertainty__ens_mve__aqsoldb', '01', 'results.json'),\n",
    "            os.path.join(EXPERIMENTS_PATH, 'results', 'quantify_uncertainty__ens_mve__aqsoldb', '02', 'results.json'),\n",
    "            os.path.join(EXPERIMENTS_PATH, 'results', 'quantify_uncertainty__ens_mve__aqsoldb', '03', 'results.json'),\n",
    "            os.path.join(EXPERIMENTS_PATH, 'results', 'quantify_uncertainty__ens_mve__aqsoldb', '04', 'results.json'),\n",
    "            os.path.join(EXPERIMENTS_PATH, 'results', 'quantify_uncertainty__ens_mve__aqsoldb', '05', 'results.json'),\n",
    "        ]\n",
    "    },\n",
    "    'lipop': {\n",
    "        'dataset': 'Lipop',\n",
    "        'property': 'logD',\n",
    "        'paths': [\n",
    "            os.path.join(EXPERIMENTS_PATH, 'results', 'quantify_uncertainty__ens_mve__lipop', '01', 'results.json'),\n",
    "            os.path.join(EXPERIMENTS_PATH, 'results', 'quantify_uncertainty__ens_mve__lipop', '02', 'results.json'),\n",
    "            os.path.join(EXPERIMENTS_PATH, 'results', 'quantify_uncertainty__ens_mve__lipop', '03', 'results.json'),\n",
    "            os.path.join(EXPERIMENTS_PATH, 'results', 'quantify_uncertainty__ens_mve__lipop', '04', 'results.json'),\n",
    "            os.path.join(EXPERIMENTS_PATH, 'results', 'quantify_uncertainty__ens_mve__lipop', '05', 'results.json'),\n",
    "        ]  \n",
    "    },\n",
    "    'compas': {\n",
    "        'dataset': 'COMPAS',\n",
    "        'property': 'Gap',\n",
    "        'paths': [\n",
    "            os.path.join(EXPERIMENTS_PATH, 'results', 'quantify_uncertainty__ens_mve__compas', '01', 'results.json'),\n",
    "            os.path.join(EXPERIMENTS_PATH, 'results', 'quantify_uncertainty__ens_mve__compas', '02', 'results.json'),\n",
    "            os.path.join(EXPERIMENTS_PATH, 'results', 'quantify_uncertainty__ens_mve__compas', '03', 'results.json'),\n",
    "            os.path.join(EXPERIMENTS_PATH, 'results', 'quantify_uncertainty__ens_mve__compas', '04', 'results.json'),\n",
    "            os.path.join(EXPERIMENTS_PATH, 'results', 'quantify_uncertainty__ens_mve__compas', '05', 'results.json'),\n",
    "        ]\n",
    "    },\n",
    "    'qm9_energy': {\n",
    "        'dataset': 'QM9',\n",
    "        'property': 'Energy',\n",
    "        'paths': [\n",
    "            os.path.join(EXPERIMENTS_PATH, 'results', 'quantify_uncertainty__ens_mve__qm9', 'energy_1', 'results.json'),\n",
    "            os.path.join(EXPERIMENTS_PATH, 'results', 'quantify_uncertainty__ens_mve__qm9', 'energy_2', 'results.json'),\n",
    "            os.path.join(EXPERIMENTS_PATH, 'results', 'quantify_uncertainty__ens_mve__qm9', 'energy_3', 'results.json'),\n",
    "            os.path.join(EXPERIMENTS_PATH, 'results', 'quantify_uncertainty__ens_mve__qm9', 'energy_4', 'results.json'),\n",
    "            os.path.join(EXPERIMENTS_PATH, 'results', 'quantify_uncertainty__ens_mve__qm9', 'energy_5', 'results.json'),\n",
    "        ]\n",
    "    },\n",
    "    'qm9_dipole': {\n",
    "        'dataset': 'QM9',\n",
    "        'property': 'Dipole Moment',\n",
    "        'paths': [\n",
    "            os.path.join(EXPERIMENTS_PATH, 'results', 'quantify_uncertainty__ens_mve__qm9', 'dipole_1', 'results.json'),\n",
    "            os.path.join(EXPERIMENTS_PATH, 'results', 'quantify_uncertainty__ens_mve__qm9', 'dipole_2', 'results.json'),\n",
    "            os.path.join(EXPERIMENTS_PATH, 'results', 'quantify_uncertainty__ens_mve__qm9', 'dipole_3', 'results.json'),\n",
    "            os.path.join(EXPERIMENTS_PATH, 'results', 'quantify_uncertainty__ens_mve__qm9', 'dipole_4', 'results.json'),\n",
    "            os.path.join(EXPERIMENTS_PATH, 'results', 'quantify_uncertainty__ens_mve__qm9', 'dipole_5', 'results.json'),\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_value(value: float | list):\n",
    "    if isinstance(value, list):\n",
    "        return value[0]\n",
    "    return value\n",
    "\n",
    "print('processing the results...')\n",
    "\n",
    "for key, data in results_map.items():\n",
    "\n",
    "    data['mae_values'] = []\n",
    "    data['r2_values'] = []\n",
    "    data['corr_values'] = []\n",
    "    data['auc_mean_values'] = []\n",
    "    data['auc_max_values'] = []\n",
    "    \n",
    "    print(f' * processing {key}')\n",
    "    for path in data['paths']:\n",
    "        \n",
    "        with open(path, mode='r') as file:\n",
    "            content = file.read()\n",
    "            results = json.loads(content)\n",
    "            \n",
    "        out_true = [get_value(result['graph_labels']) for result in results]\n",
    "        out_pred = [get_value(result['prediction']) for result in results]\n",
    "            \n",
    "        # calculating the prediction performance metrics (MAE & R2)\n",
    "        mae_value = mean_absolute_error(out_true, out_pred)\n",
    "        r2_value = r2_score(out_true, out_pred)\n",
    "        data['mae_values'].append(mae_value)\n",
    "        data['r2_values'].append(r2_value)\n",
    "        \n",
    "        # as a setup we then have to calculate the error between the prediction and the true value\n",
    "        # and also get the uncertainty values from the results directly\n",
    "        for result in results:\n",
    "            result['error'] = abs(get_value(result['graph_labels']) - get_value(result['prediction']))\n",
    "        \n",
    "        errors = np.array([get_value(result['error']) for result in results])\n",
    "        uncertainties = np.array([get_value(result['uncertainty']) for result in results])\n",
    "        \n",
    "        # then we can calculate the correlation between the error and the uncertainty\n",
    "        corr_value = np.corrcoef(errors, uncertainties)[0, 1]\n",
    "        data['corr_values'].append(corr_value)\n",
    "        \n",
    "        # finally we can use the error and uncertainty values to calculate the EUT-AUC\n",
    "        ths, rds = threshold_error_reduction(uncertainties, errors, error_func=np.mean, num_bins=NUM_BINS)\n",
    "        auc_mean_value = auc(ths, rds)\n",
    "        data['auc_mean_values'].append(auc_mean_value)\n",
    "        \n",
    "        ths, rds =  threshold_error_reduction(uncertainties, errors, error_func=np.max, num_bins=NUM_BINS)\n",
    "        auc_max_value = auc(ths, rds)\n",
    "        data['auc_max_values'].append(auc_max_value)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summarizing the results...\n"
     ]
    }
   ],
   "source": [
    "print('summarizing the results...')\n",
    "\n",
    "rows = []\n",
    "for key, data in results_map.items():\n",
    "    row = [\n",
    "        data['dataset'],\n",
    "        data['property'],\n",
    "        data['r2_values'],\n",
    "        data['corr_values'],\n",
    "        data['auc_mean_values'],\n",
    "        data['auc_max_values'],\n",
    "    ]\n",
    "    rows.append(row)\n",
    "\n",
    "_, content = latex_table(\n",
    "    column_names=['Dataset', 'Property', r'$R^2$', r'$\\rho$', r'$\\text{UER-AUC}_{\\text{mean}}$', r'$\\text{UER-AUC}_{\\text{max}}$'],\n",
    "    rows=rows,\n",
    ")\n",
    "    \n",
    "tex_path = os.path.join(PATH, 'table_real.tex')\n",
    "with open(tex_path, mode='w') as file:\n",
    "    file.write(content)\n",
    "    \n",
    "pdf_path = os.path.join(PATH, 'table_real.pdf')\n",
    "render_latex({'content': content}, pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
